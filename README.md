# Real-Time Speech Enhancement: Adaptive Filtering vs. Machine Learning  

## Project Overview  
This project explores real-time speech enhancement techniques aimed at improving intelligibility in noisy environments. Two approaches are implemented and compared:  

- **Adaptive Filtering**: Classical DSP methods including Wiener filtering and Normalized Least Mean Squares (NLMS).  
- **Machine Learning**: A shallow neural network model designed to learn time-frequency masks for noise suppression.  

The goal is to evaluate the trade-offs between computationally efficient adaptive filters and data-driven machine learning methods, particularly for real-time and resource-constrained applications.  

---

## Tools and Platforms  
- **MATLAB** (Audio Toolbox, Deep Learning Toolbox)  
- **Datasets**: NOIZEUS and DEMAND noisy speech corpora  

---

## Deliverables  
- MATLAB prototype with both approaches  
- Comparative analysis with metrics such as:  
  - Signal-to-Noise Ratio (SNR) improvement  
  - Perceptual Evaluation of Speech Quality (PESQ)  
- Final report (research paper style)  
- Video demonstration of before/after results  
- Public GitHub repository with documented code  

---

## Timeline (Weeks)  
- **6–7**: Literature review, MATLAB setup, dataset preparation  
- **8–9**: Implement and test adaptive filtering methods  
- **10–11**: Design, train, and test machine learning model  
- **12**: Comparative evaluation, report writing, video demo  

---

## Author  
**Alaa Aldirani**  
- SID: 490627356  
- GitHub: [Dirani0437](https://github.com/Dirani0437/elec5305-project-490627356)  

---

## References  
- Loizou, P. C. *Speech Enhancement: Theory and Practice.* CRC Press, 2013.  
- Ephraim, Y., & Malah, D. (1984). *Speech enhancement using a minimum mean-square error short-time spectral amplitude estimator.* IEEE Transactions on Acoustics, Speech, and Signal Processing, 32(6), 1109–1121.  
- Wang, D., & Chen, J. (2018). *Supervised speech separation based on deep learning: An overview.* IEEE/ACM Transactions on Audio, Speech, and Language Processing, 26(10), 1702–1726.  
